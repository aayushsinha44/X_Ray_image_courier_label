{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_desc = pd.read_csv('x_ray_image_recognition_data/product_description_and_categories.csv')\n",
    "df_train = pd.read_csv('x_ray_image_recognition_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_description</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neo Fresh 245 L, 3 Star Double Door Frost Free...</td>\n",
       "      <td>Electronics and Appliances</td>\n",
       "      <td>Home and Kitchen Appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Professional 340 L, 3 Star Double Door Frost F...</td>\n",
       "      <td>Electronics and Appliances</td>\n",
       "      <td>Home and Kitchen Appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Protton 300 L, 3 Door Frost Free Refrigerator-...</td>\n",
       "      <td>Electronics and Appliances</td>\n",
       "      <td>Home and Kitchen Appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ace Stainfree 8 Kg Semi Automatic Washing Mach...</td>\n",
       "      <td>Electronics and Appliances</td>\n",
       "      <td>Washing Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Protton 260 L, 3 Door Frost Free Refrigerator-...</td>\n",
       "      <td>Electronics and Appliances</td>\n",
       "      <td>Washing Machines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 product_description  \\\n",
       "0  Neo Fresh 245 L, 3 Star Double Door Frost Free...   \n",
       "1  Professional 340 L, 3 Star Double Door Frost F...   \n",
       "2  Protton 300 L, 3 Door Frost Free Refrigerator-...   \n",
       "3  Ace Stainfree 8 Kg Semi Automatic Washing Mach...   \n",
       "4  Protton 260 L, 3 Door Frost Free Refrigerator-...   \n",
       "\n",
       "                     category                 sub_category  \n",
       "0  Electronics and Appliances  Home and Kitchen Appliances  \n",
       "1  Electronics and Appliances  Home and Kitchen Appliances  \n",
       "2  Electronics and Appliances  Home and Kitchen Appliances  \n",
       "3  Electronics and Appliances             Washing Machines  \n",
       "4  Electronics and Appliances             Washing Machines  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_ray_image_file_name</th>\n",
       "      <th>product_description</th>\n",
       "      <th>x_ray_product_description_match_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Acer Aspire SW3-016 10.1-inch Laptop (Atom x5-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>Apple iPhone 6S 64 GB (Golden)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>7th ,8th(2) , 1st , 5th</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>10th Class</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>4th , 5th &amp; English Class</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  x_ray_image_file_name                                product_description  \\\n",
       "0                 1.jpg  Acer Aspire SW3-016 10.1-inch Laptop (Atom x5-...   \n",
       "1                 2.jpg                     Apple iPhone 6S 64 GB (Golden)   \n",
       "2                 4.jpg                            7th ,8th(2) , 1st , 5th   \n",
       "3                 5.jpg                                         10th Class   \n",
       "4                 6.jpg                          4th , 5th & English Class   \n",
       "\n",
       "   x_ray_product_description_match_status  \n",
       "0                                    True  \n",
       "1                                    True  \n",
       "2                                    True  \n",
       "3                                    True  \n",
       "4                                    True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_category = df_desc.iloc[:,1].values\n",
    "X_desc = df_desc.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "import webcolors\n",
    "import string\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_text_special(text):\n",
    "    # handle format rid- , , product- , ,\n",
    "    text = re.sub('\"', '' ,text)\n",
    "    if text.split(' ')[0] == \"rid-\":\n",
    "        text = re.sub('\\(', '', text)\n",
    "        text = re.sub('\\)', '', text)\n",
    "        text = text.strip(\")\")\n",
    "        w = text.split(' ')\n",
    "        t = []\n",
    "        for i in range(len(w)):\n",
    "            if w[i] == \"rid-\":\n",
    "                i = i+1\n",
    "                while(True):\n",
    "                    t.append(w[i])\n",
    "                    i += 1\n",
    "                    if w[i] == \"product-\":\n",
    "                        break\n",
    "            if w[i] == \"product-\":\n",
    "                for j in range(i+1, len(w)):\n",
    "                    t.append(w[j])\n",
    "                break\n",
    "        t = ' '.join(t)\n",
    "        t = t.split(',')\n",
    "        t = [ti.strip() for ti in t]\n",
    "        t = [ti.lower() for ti in t if ti != '']\n",
    "        return t\n",
    "    text = re.sub(r\"[\\(\\[]*?[\\)\\]]\", \"\", text)\n",
    "    #handling , , , ,\n",
    "    if len(text.split(',')) > 3:\n",
    "        t = text.split(',')\n",
    "        t = [ti.strip() for ti in t]\n",
    "        t = [ti.lower() for ti in t if ti != '']\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[\\(\\[]*?[\\)\\]]\", \"\", text)\n",
    "    text = re.sub(\"months\", \"\", text)\n",
    "    text = re.sub(r'\\d+', \"\", text) # remove numbers\n",
    "    words = text.split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in words]\n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(word) for word in stripped]\n",
    "    words = [word.lower() for word in stemmed]\n",
    "    words = [word for word in words if word not in webcolors.CSS3_NAMES_TO_HEX] # remove colors \n",
    "    stop_words = stopwords.words('english')\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_desc = []\n",
    "y_train_category = []\n",
    "for i in range(len(X_desc)):\n",
    "    print(\"Processing text %d\" %(i+1))\n",
    "    text = X_desc[i]\n",
    "    if text.split(' ')[0] == \"rid-\" or len(text.split(',')) > 3:\n",
    "        t = process_text_special(text)\n",
    "        for j in t:\n",
    "            _t = clean_text(j)\n",
    "            X_train_desc.append(_t)\n",
    "            y_train_category.append(X_category[i])\n",
    "    else:\n",
    "        _t = clean_text(text)\n",
    "        X_train_desc.append(_t)\n",
    "        y_train_category.append(X_category[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81299"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21603\n"
     ]
    }
   ],
   "source": [
    "max_len = -1\n",
    "for i in X_train_desc:\n",
    "    max_len = max(max_len, len(i))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69929\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "threshold = 100\n",
    "for i in X_train_desc:\n",
    "    if(len(i)<= threshold):\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 100\n",
    "X_train_desc_th = []\n",
    "y_train_category_th = []\n",
    "for i in range(len(X_train_desc)):\n",
    "    if(len(X_train_desc[i]) <= threshold):\n",
    "        X_train_desc_th.append(X_train_desc[i])\n",
    "        y_train_category_th.append(y_train_category[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28426\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for i in X_train_desc_th:\n",
    "    for j in i.split():\n",
    "        vocab.add(j)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28426\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "int2word = {}\n",
    "for i in range(len(vocab)):\n",
    "    word2int[vocab[i]] = i\n",
    "    int2word[i] = vocab[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2int['<UNK>'] = len(word2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_seq = []\n",
    "for i in X_train_desc_th:\n",
    "    _t  = []\n",
    "    for j in i.split():\n",
    "        _t.append(word2int[j])\n",
    "    X_train_seq.append(_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "max_length = -1\n",
    "for i in X_train_seq:\n",
    "    max_length = max(max_length, len(i))\n",
    "print (max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_seq = pad_sequences(X_train_seq, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_seq = np.array(X_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69929, 25)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2int_category = {}\n",
    "int2word_category = {}\n",
    "category = set()\n",
    "sub_category = set()\n",
    "for i in range(len(y_train_category_th)):\n",
    "    category.add(y_train_category_th[i])\n",
    "category = list(category)\n",
    "for i in range(len(category)):\n",
    "    word2int_category[category[i]] = i\n",
    "    int2word_category[i] = category[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Movies, Music and Video Games',\n",
       " 1: 'Mobile Phone, Tablets and Accessories',\n",
       " 2: 'Electronics and Appliances',\n",
       " 3: 'Health and Wellness',\n",
       " 4: 'Stationery and Office Products',\n",
       " 5: 'Sports and Outdoors',\n",
       " 6: 'Industrial and Scientific Goods',\n",
       " 7: 'Books, Software and E-learning',\n",
       " 8: 'Apparel and Accessories',\n",
       " 9: 'Baby Care',\n",
       " 10: 'Stationery and office Products',\n",
       " 11: ' Gifts ',\n",
       " 12: 'Grocery and Gourmet Food',\n",
       " 13: 'Camera and Photos',\n",
       " 14: 'Toys and Games',\n",
       " 15: 'Uncategorized',\n",
       " 16: 'Computers, Laptops and Accessories',\n",
       " 17: 'Watches, Eyewear and Jewellery',\n",
       " 18: 'Shoes and Footwear',\n",
       " 19: 'Tools and Hardware',\n",
       " 20: 'Handbags, Bags and Luggage',\n",
       " 21: 'Pet Supplies',\n",
       " 22: 'Automotive',\n",
       " 23: 'Beauty Products and Personal Care',\n",
       " 24: 'Musical Instruments',\n",
       " 25: 'Home and Kitchen'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2word_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_category_seq = []\n",
    "for i in range(len(y_train_category_th)):\n",
    "    #print(y_train_category_th[i])\n",
    "    y_train_category_seq.append(word2int_category[y_train_category_th[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_category_seq = to_categorical(y_train_category_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_category_seq[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_seq_1 , X_test_seq_1, y_train_category_seq_1, y_test_category_seq_1 = train_test_split(X_train_seq,\n",
    "                                                                                               y_train_category_seq,\n",
    "                                                                                               test_size = 0.2, \n",
    "                                                                                               random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69929, 25)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size=len(word2int)\n",
    "input_length=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 25, 64)            1819328   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               409856    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 26)                6682      \n",
      "=================================================================\n",
      "Total params: 2,301,658\n",
      "Trainable params: 2,301,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_category = Sequential()\n",
    "model_category.add(Embedding(vocab_size, 64, input_length=input_length))\n",
    "model_category.add(Flatten())\n",
    "model_category.add(Dense(256,kernel_initializer='normal', activation='relu', input_dim = input_length))\n",
    "model_category.add(Dense(256,kernel_initializer='normal', activation='relu'))\n",
    "#model_category.add(Dense(1024,kernel_initializer='normal', activation='relu'))\n",
    "model_category.add(Dense(26,activation='sigmoid'))\n",
    "model_category.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model_category.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69929 samples, validate on 13986 samples\n",
      "Epoch 1/2\n",
      "69929/69929 [==============================] - 78s 1ms/step - loss: 0.6324 - acc: 0.8082 - val_loss: 0.2187 - val_acc: 0.9309\n",
      "Epoch 2/2\n",
      "69929/69929 [==============================] - 66s 943us/step - loss: 0.2147 - acc: 0.9327 - val_loss: 0.1089 - val_acc: 0.9644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8d45c5588>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_category.fit(X_train_seq, y_train_category_seq,\n",
    "                   epochs=2,  \n",
    "                   validation_data=[X_test_seq_1, y_test_category_seq_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13488\n",
      "498\n",
      "Accuracy 0.9643929643929644\n"
     ]
    }
   ],
   "source": [
    "pred = model_category.predict(X_test_seq_1)\n",
    "\n",
    "correct_ans = 0\n",
    "wrong_ans = 0\n",
    "ans = []\n",
    "for i in range(len(pred)):\n",
    "    max_pos = 0\n",
    "    max_val = -10000000000000000000000\n",
    "    for j in range(len(pred[i])):\n",
    "        if max_val < pred[i][j]:\n",
    "            max_val = pred[i][j]\n",
    "            max_pos = j\n",
    "    ans.append(max_pos)\n",
    "    if y_test_category_seq_1[i][max_pos] == 1:\n",
    "        correct_ans += 1\n",
    "    else:\n",
    "        wrong_ans += 1\n",
    "print(correct_ans)\n",
    "print(wrong_ans)\n",
    "print(\"Accuracy\", 1.0 * correct_ans / (wrong_ans + correct_ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc_train_load = df_train.iloc[:,1].values\n",
    "image_path_load = df_train.iloc[:,0].values\n",
    "y_train_load = df_train.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103464\n",
      "9498\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "count_false = 0\n",
    "for i in y_train_load:\n",
    "    if i == True:\n",
    "        count_true += 1\n",
    "    else:\n",
    "        count_false += 1\n",
    "print(count_true)\n",
    "print(count_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%d nan fixed 2\n"
     ]
    }
   ],
   "source": [
    "# handling nan\n",
    "nan_count = 0\n",
    "a = desc_train_load[48066] #nan values\n",
    "for i in range(len(desc_train_load)):\n",
    "    if desc_train_load[i] is a:\n",
    "        desc_train_load[i] = \"none\"\n",
    "        nan_count += 1\n",
    "print(\"%d nan fixed\",  (nan_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_train = []\n",
    "for i in range(len(desc_train_load)):\n",
    "    print(\"Processing text\",i+1)\n",
    "    desc_train.append(clean_text(desc_train_load[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_desc_category = []\n",
    "image_path = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(desc_train)):\n",
    "    if desc_train[i] != 'none' and y_train_load[i] != False:\n",
    "        _t  = []\n",
    "        for j in desc_train[i].split():\n",
    "            if j not in word2int:\n",
    "                _t.append(word2int['<UNK>'])\n",
    "            else:\n",
    "                _t.append(word2int[j])\n",
    "        y_desc_category.append(_t)\n",
    "        image_path.append(image_path_load[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_desc_category = pad_sequences(y_desc_category, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_desc_category_result = model_category.predict(y_desc_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cat = []\n",
    "for i in range(len(y_desc_category_result)):\n",
    "    max_pos = 0\n",
    "    max_val = -1000000000000000000\n",
    "    for j in range(len(y_desc_category_result[i])):\n",
    "        if max_val < y_desc_category_result[i][j]:\n",
    "            max_val = y_desc_category_result[i][j]\n",
    "            max_pos = j\n",
    "    y_cat.append(max_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_count = {}\n",
    "for i in range(0,26):\n",
    "    cat_count[i] = 0\n",
    "for i in range(len(y_cat)):\n",
    "        cat_count[y_cat[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 52574,\n",
       " 2: 1751,\n",
       " 3: 419,\n",
       " 4: 462,\n",
       " 5: 1280,\n",
       " 6: 7,\n",
       " 7: 1246,\n",
       " 8: 2459,\n",
       " 9: 4,\n",
       " 10: 0,\n",
       " 11: 77,\n",
       " 12: 0,\n",
       " 13: 2206,\n",
       " 14: 240,\n",
       " 15: 14293,\n",
       " 16: 14400,\n",
       " 17: 7811,\n",
       " 18: 1094,\n",
       " 19: 70,\n",
       " 20: 221,\n",
       " 21: 1,\n",
       " 22: 437,\n",
       " 23: 775,\n",
       " 24: 3,\n",
       " 25: 1632}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from keras.constraints import maxnorm\n",
    "#from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(image_path)):\n",
    "    print(\"Processing\",image_path[i], i+1)\n",
    "    train_image = image.load_img('x_ray_image_recognition_data/x_ray_images/train_xray_images/'+image_path[i], target_size = (32, 32))\n",
    "    train_image = image.img_to_array(train_image)\n",
    "    train_image = np.expand_dims(train_image, axis = 0)\n",
    "    X_train.append(train_image)\n",
    "    y_train.append(y_desc_category_result[i])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(X_train, open(\"X_train.pickle\", \"wb\"))\n",
    "pickle.dump(y_train, open(\"y_train.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pickle.load(open(\"X_train.pickle\", \"rb\"))\n",
    "y_train = pickle.load(open(\"y_train.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103462, 26)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(y_cat)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_train = y_train.astype('int32')\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103462, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X_temp = []\n",
    "for i in range(len(X_train)):\n",
    "    X_temp.append(X_train[i].reshape(32,32,3))\n",
    "X_train = np.array(X_temp)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize inputs from 0-255 to 0.0 - 1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 26)                13338     \n",
      "=================================================================\n",
      "Total params: 2,923,322\n",
      "Trainable params: 2,923,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(32,32,3), activation='relu', padding='same'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(26, activation='softmax'))\n",
    "\n",
    "# Compiling model\n",
    "epochs = 10\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(classifier.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82769 samples, validate on 20693 samples\n",
      "Epoch 1/10\n",
      "82769/82769 [==============================] - 1042s 13ms/step - loss: 1.4030 - acc: 0.6010 - val_loss: 1.1821 - val_acc: 0.6584\n",
      "Epoch 2/10\n",
      "15584/82769 [====>.........................] - ETA: 13:32 - loss: 1.1817 - acc: 0.6540"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(X_test).astype('int32')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('x_ray_image_recognition_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc_test_load = df_test.iloc[:, 1].values\n",
    "image_path_load_test = df_test.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_test = []\n",
    "for i in range(len(desc_test_load)):\n",
    "    print(\"Processing text\",i+1)\n",
    "    desc_test.append(clean_text(desc_test_load[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_desc_category_test = []\n",
    "\n",
    "for i in range(len(desc_test)):\n",
    "    _t  = []\n",
    "    for j in desc_test[i].split():\n",
    "        if j not in word2int:\n",
    "            _t.append(word2int['<UNK>'])\n",
    "        else:\n",
    "            _t.append(word2int[j])\n",
    "    y_desc_category_test.append(_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_desc_category_test = pad_sequences(y_desc_category_test, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_desc_category_result_test = model_category.predict(y_desc_category_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cat_test = []\n",
    "for i in range(len(y_desc_category_result_test)):\n",
    "    max_pos = 0\n",
    "    max_val = -1000000000000000000\n",
    "    for j in range(len(y_desc_category_result_test[i])):\n",
    "        if max_val < y_desc_category_result_test[i][j]:\n",
    "            max_val = y_desc_category_result_test[i][j]\n",
    "            max_pos = j\n",
    "    y_cat_test.append(max_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_true = 0\n",
    "y_pred = []\n",
    "for i in range(len(y_cat_test)):\n",
    "    test_image = image.load_img('x_ray_image_recognition_data/x_ray_images/test_xray_images/'+image_path_load_test[i], target_size = (32, 32))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = classifier.predict(test_image).astype('int32')\n",
    "    max_pos = 0\n",
    "    max_val = -1000000000000000000\n",
    "    for j in range(len(result[0])):\n",
    "        if max_val < result[0][j]:\n",
    "            max_val = result[0][j]\n",
    "            max_pos = j\n",
    "    if y_cat_test[i] == max_pos:\n",
    "        y_pred.append('True')\n",
    "        count_true += 1\n",
    "    else:\n",
    "        y_pred.append('False')\n",
    "    print(result[0])\n",
    "    print(i, y_cat_test[i], max_pos, count_true)\n",
    "print(count_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['x_ray_image_file_name'] = image_path_load_test\n",
    "df['x_ray_product_description_match_status'] = y_pred\n",
    "df.to_csv('output_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
