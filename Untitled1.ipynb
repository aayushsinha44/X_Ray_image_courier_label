{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_desc = pd.read_csv('x_ray_image_recognition_data/product_description_and_categories.csv')\n",
    "df_train = pd.read_csv('x_ray_image_recognition_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_description</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neo Fresh 245 L, 3 Star Double Door Frost Free...</td>\n",
       "      <td>Electronics and Appliances</td>\n",
       "      <td>Home and Kitchen Appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Professional 340 L, 3 Star Double Door Frost F...</td>\n",
       "      <td>Electronics and Appliances</td>\n",
       "      <td>Home and Kitchen Appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Protton 300 L, 3 Door Frost Free Refrigerator-...</td>\n",
       "      <td>Electronics and Appliances</td>\n",
       "      <td>Home and Kitchen Appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ace Stainfree 8 Kg Semi Automatic Washing Mach...</td>\n",
       "      <td>Electronics and Appliances</td>\n",
       "      <td>Washing Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Protton 260 L, 3 Door Frost Free Refrigerator-...</td>\n",
       "      <td>Electronics and Appliances</td>\n",
       "      <td>Washing Machines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 product_description  \\\n",
       "0  Neo Fresh 245 L, 3 Star Double Door Frost Free...   \n",
       "1  Professional 340 L, 3 Star Double Door Frost F...   \n",
       "2  Protton 300 L, 3 Door Frost Free Refrigerator-...   \n",
       "3  Ace Stainfree 8 Kg Semi Automatic Washing Mach...   \n",
       "4  Protton 260 L, 3 Door Frost Free Refrigerator-...   \n",
       "\n",
       "                     category                 sub_category  \n",
       "0  Electronics and Appliances  Home and Kitchen Appliances  \n",
       "1  Electronics and Appliances  Home and Kitchen Appliances  \n",
       "2  Electronics and Appliances  Home and Kitchen Appliances  \n",
       "3  Electronics and Appliances             Washing Machines  \n",
       "4  Electronics and Appliances             Washing Machines  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_ray_image_file_name</th>\n",
       "      <th>product_description</th>\n",
       "      <th>x_ray_product_description_match_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Acer Aspire SW3-016 10.1-inch Laptop (Atom x5-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>Apple iPhone 6S 64 GB (Golden)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>7th ,8th(2) , 1st , 5th</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>10th Class</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>4th , 5th &amp; English Class</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  x_ray_image_file_name                                product_description  \\\n",
       "0                 1.jpg  Acer Aspire SW3-016 10.1-inch Laptop (Atom x5-...   \n",
       "1                 2.jpg                     Apple iPhone 6S 64 GB (Golden)   \n",
       "2                 4.jpg                            7th ,8th(2) , 1st , 5th   \n",
       "3                 5.jpg                                         10th Class   \n",
       "4                 6.jpg                          4th , 5th & English Class   \n",
       "\n",
       "   x_ray_product_description_match_status  \n",
       "0                                    True  \n",
       "1                                    True  \n",
       "2                                    True  \n",
       "3                                    True  \n",
       "4                                    True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_category = df_desc.iloc[:,1].values\n",
    "X_desc = df_desc.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "import webcolors\n",
    "import string\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_text_special(text):\n",
    "    # handle format rid- , , product- , ,\n",
    "    text = re.sub('\"', '' ,text)\n",
    "    if text.split(' ')[0] == \"rid-\":\n",
    "        text = re.sub('\\(', '', text)\n",
    "        text = re.sub('\\)', '', text)\n",
    "        text = text.strip(\")\")\n",
    "        w = text.split(' ')\n",
    "        t = []\n",
    "        for i in range(len(w)):\n",
    "            if w[i] == \"rid-\":\n",
    "                i = i+1\n",
    "                while(True):\n",
    "                    t.append(w[i])\n",
    "                    i += 1\n",
    "                    if w[i] == \"product-\":\n",
    "                        break\n",
    "            if w[i] == \"product-\":\n",
    "                for j in range(i+1, len(w)):\n",
    "                    t.append(w[j])\n",
    "                break\n",
    "        t = ' '.join(t)\n",
    "        t = t.split(',')\n",
    "        t = [ti.strip() for ti in t]\n",
    "        t = [ti.lower() for ti in t if ti != '']\n",
    "        return t\n",
    "    text = re.sub(r\"[\\(\\[]*?[\\)\\]]\", \"\", text)\n",
    "    #handling , , , ,\n",
    "    if len(text.split(',')) > 3:\n",
    "        t = text.split(',')\n",
    "        t = [ti.strip() for ti in t]\n",
    "        t = [ti.lower() for ti in t if ti != '']\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[\\(\\[]*?[\\)\\]]\", \"\", text)\n",
    "    text = re.sub(\"months\", \"\", text)\n",
    "    text = re.sub(r'\\d+', \"\", text) # remove numbers\n",
    "    words = text.split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in words]\n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(word) for word in stripped]\n",
    "    words = [word.lower() for word in stemmed]\n",
    "    words = [word for word in words if word not in webcolors.CSS3_NAMES_TO_HEX] # remove colors \n",
    "    stop_words = stopwords.words('english')\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_desc = []\n",
    "y_train_category = []\n",
    "for i in range(len(X_desc)):\n",
    "    print(\"Processing text %d\" %(i+1))\n",
    "    text = X_desc[i]\n",
    "    if text.split(' ')[0] == \"rid-\" or len(text.split(',')) > 3:\n",
    "        t = process_text_special(text)\n",
    "        for j in t:\n",
    "            _t = clean_text(j)\n",
    "            X_train_desc.append(_t)\n",
    "            y_train_category.append(X_category[i])\n",
    "    else:\n",
    "        _t = clean_text(text)\n",
    "        X_train_desc.append(_t)\n",
    "        y_train_category.append(X_category[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21603\n"
     ]
    }
   ],
   "source": [
    "max_len = -1\n",
    "for i in X_train_desc:\n",
    "    max_len = max(max_len, len(i))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['profession l star doubl door frost free refriger intellifresh sensorsalpha steel',\n",
       " 'protton l door frost free refrigeratoralpha steel',\n",
       " 'ace stainfre kg semi automat wash machineflora',\n",
       " 'protton l door frost free refrigeratorsteel knight bloomwash world seri kg fulli automat top load wash machinegraphiteprotton l door frost free refrigeratorsteel knight bloomwash world seri kg fulli automat top load wash machinegraphit']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_desc[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453709"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442204\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "threshold = 100\n",
    "for i in X_train_desc:\n",
    "    if(len(i) <= threshold):\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 100\n",
    "X_train_desc_th = []\n",
    "y_train_category_th = []\n",
    "for i in range(len(X_train_desc)):\n",
    "    if(len(X_train_desc[i]) <= threshold):\n",
    "        X_train_desc_th.append(X_train_desc[i])\n",
    "        y_train_category_th.append(y_train_category[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for i in X_train_desc_th:\n",
    "    for j in i.split():\n",
    "        vocab.add(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39530\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "int2word = {}\n",
    "for i in range(len(vocab)):\n",
    "    word2int[vocab[i]] = i\n",
    "    int2word[i] = vocab[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2int['<UNK>'] = len(word2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_seq = []\n",
    "for i in X_train_desc_th:\n",
    "    _t  = []\n",
    "    for j in i.split():\n",
    "        _t.append(word2int[j])\n",
    "    X_train_seq.append(_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3326, 37676, 28455, 21114, 34841, 33345, 7633, 31888, 28634, 24427, 18207],\n",
       " [35168, 37676, 34841, 33345, 7633, 18498, 18207],\n",
       " [24253, 3405, 23907, 23384, 14902, 33005, 9512],\n",
       " [4580, 37676, 37111, 14911]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "max_length = -1\n",
    "for i in X_train_seq:\n",
    "    max_length = max(max_length, len(i))\n",
    "print (max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ipaki', 'cullot', 'xdn', 'btnplkt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aayush\\AppData\\Local\\conda\\conda\\envs\\my_root_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_seq = pad_sequences(X_train_seq, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,  3326, 37676, 28455, 21114,\n",
       "        34841, 33345,  7633, 31888, 28634, 24427, 18207],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "        35168, 37676, 34841, 33345,  7633, 18498, 18207],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "        24253,  3405, 23907, 23384, 14902, 33005,  9512],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,  4580, 37676, 37111, 14911]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442204, 25)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2int_category = {}\n",
    "int2word_category = {}\n",
    "category = set()\n",
    "sub_category = set()\n",
    "for i in range(len(y_train_category_th)):\n",
    "    category.add(y_train_category_th[i])\n",
    "category = list(category)\n",
    "for i in range(len(category)):\n",
    "    word2int_category[category[i]] = i\n",
    "    int2word_category[i] = category[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' Gifts ': 19,\n",
       " 'Apparel and Accessories': 12,\n",
       " 'Automotive': 0,\n",
       " 'Baby Care': 15,\n",
       " 'Beauty Products and Personal Care': 10,\n",
       " 'Books, Software and E-learning': 4,\n",
       " 'Camera and Photos': 14,\n",
       " 'Computers, Laptops and Accessories': 22,\n",
       " 'Electronics and Appliances': 6,\n",
       " 'Grocery and Gourmet Food': 20,\n",
       " 'Handbags, Bags and Luggage': 23,\n",
       " 'Health and Wellness': 8,\n",
       " 'Home and Kitchen': 1,\n",
       " 'Industrial and Scientific Goods': 7,\n",
       " 'Mobile Phone, Tablets and Accessories': 16,\n",
       " 'Movies, Music and Video Games': 5,\n",
       " 'Musical Instruments': 13,\n",
       " 'Pet Supplies': 2,\n",
       " 'Shoes and Footwear': 3,\n",
       " 'Sports and Outdoors': 24,\n",
       " 'Stationery and Office Products': 11,\n",
       " 'Stationery and office Products': 17,\n",
       " 'Tools and Hardware': 18,\n",
       " 'Toys and Games': 9,\n",
       " 'Uncategorized': 25,\n",
       " 'Watches, Eyewear and Jewellery': 21}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_category_seq = []\n",
    "for i in range(len(y_train_category_th)):\n",
    "    #print(y_train_category_th[i])\n",
    "    y_train_category_seq.append(word2int_category[y_train_category_th[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_category_seq = to_categorical(y_train_category_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_category_seq[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_seq_1 , X_test_seq_1, y_train_category_seq_1, y_test_category_seq_1 = train_test_split(X_train_seq,\n",
    "                                                                                               y_train_category_seq,\n",
    "                                                                                               test_size = 0.2, \n",
    "                                                                                               random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size=39531\n",
    "input_length=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 64)            2529984   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               409856    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 26)                6682      \n",
      "=================================================================\n",
      "Total params: 3,012,314\n",
      "Trainable params: 3,012,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_category = Sequential()\n",
    "model_category.add(Embedding(vocab_size, 64, input_length=input_length))\n",
    "model_category.add(Flatten())\n",
    "model_category.add(Dense(256,kernel_initializer='normal', activation='relu', input_dim = input_length))\n",
    "model_category.add(Dense(256,kernel_initializer='normal', activation='relu'))\n",
    "#model_category.add(Dense(1024,kernel_initializer='normal', activation='relu'))\n",
    "model_category.add(Dense(26,activation='sigmoid'))\n",
    "model_category.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model_category.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 442204 samples, validate on 88441 samples\n",
      "Epoch 1/2\n",
      "442204/442204 [==============================] - 459s 1ms/step - loss: 0.3386 - acc: 0.9067 - val_loss: 0.2306 - val_acc: 0.9332\n",
      "Epoch 2/2\n",
      "442204/442204 [==============================] - 569s 1ms/step - loss: 0.2405 - acc: 0.9314 - val_loss: 0.2014 - val_acc: 0.9407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6550966b00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_category.fit(X_train_seq, y_train_category_seq,\n",
    "                   epochs=2,  \n",
    "                   validation_data=[X_test_seq_1, y_test_category_seq_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83198\n",
      "5243\n",
      "Accuracy 0.9407175405072308\n"
     ]
    }
   ],
   "source": [
    "pred = model_category.predict(X_test_seq_1)\n",
    "\n",
    "correct_ans = 0\n",
    "wrong_ans = 0\n",
    "ans = []\n",
    "for i in range(len(pred)):\n",
    "    max_pos = 0\n",
    "    max_val = -10000000000000000000000\n",
    "    for j in range(len(pred[i])):\n",
    "        if max_val < pred[i][j]:\n",
    "            max_val = pred[i][j]\n",
    "            max_pos = j\n",
    "    ans.append(max_pos)\n",
    "    if y_test_category_seq_1[i][max_pos] == 1:\n",
    "        correct_ans += 1\n",
    "    else:\n",
    "        wrong_ans += 1\n",
    "print(correct_ans)\n",
    "print(wrong_ans)\n",
    "print(\"Accuracy\", 1.0 * correct_ans / (wrong_ans + correct_ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc_train_load = df_train.iloc[:,1].values\n",
    "image_path_load = df_train.iloc[:,0].values\n",
    "y_train_load = df_train.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103464\n",
      "9498\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "count_false = 0\n",
    "for i in y_train_load:\n",
    "    if i == True:\n",
    "        count_true += 1\n",
    "    else:\n",
    "        count_false += 1\n",
    "print(count_true)\n",
    "print(count_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%d nan fixed 2\n"
     ]
    }
   ],
   "source": [
    "# handling nan\n",
    "nan_count = 0\n",
    "a = desc_train_load[48066] #nan values\n",
    "for i in range(len(desc_train_load)):\n",
    "    if desc_train_load[i] is a:\n",
    "        desc_train_load[i] = \"none\"\n",
    "        nan_count += 1\n",
    "print(\"%d nan fixed\",  (nan_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_train = []\n",
    "for i in range(len(desc_train_load)):\n",
    "    print(\"Processing text\",i+1)\n",
    "    desc_train.append(clean_text(desc_train_load[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_desc_category = []\n",
    "image_path = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(desc_train)):\n",
    "    if desc_train[i] != 'none' and y_train_load[i] != False:\n",
    "        _t  = []\n",
    "        for j in desc_train[i].split():\n",
    "            if j not in word2int:\n",
    "                _t.append(word2int['<UNK>'])\n",
    "            else:\n",
    "                _t.append(word2int[j])\n",
    "        y_desc_category.append(_t)\n",
    "        image_path.append(image_path_load[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_desc_category = pad_sequences(y_desc_category, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_desc_category_result = model_category.predict(y_desc_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_cat = []\n",
    "for i in range(len(y_desc_category_result)):\n",
    "    max_pos = 0\n",
    "    max_val = -1000000000000000000\n",
    "    for j in range(len(y_desc_category_result[i])):\n",
    "        if max_val < y_desc_category_result[i][j]:\n",
    "            max_val = y_desc_category_result[i][j]\n",
    "            max_pos = j\n",
    "    y_cat.append(max_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_count = {}\n",
    "for i in range(0,26):\n",
    "    cat_count[i] = 0\n",
    "for i in range(len(y_cat)):\n",
    "        cat_count[y_cat[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 419,\n",
       " 1: 1555,\n",
       " 2: 9,\n",
       " 3: 891,\n",
       " 4: 1049,\n",
       " 5: 0,\n",
       " 6: 1661,\n",
       " 7: 12,\n",
       " 8: 521,\n",
       " 9: 156,\n",
       " 10: 869,\n",
       " 11: 461,\n",
       " 12: 3327,\n",
       " 13: 4,\n",
       " 14: 2219,\n",
       " 15: 2,\n",
       " 16: 51961,\n",
       " 17: 0,\n",
       " 18: 63,\n",
       " 19: 1,\n",
       " 20: 0,\n",
       " 21: 7172,\n",
       " 22: 14362,\n",
       " 23: 178,\n",
       " 24: 1341,\n",
       " 25: 15229}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import np_utils\n",
    "from keras.constraints import maxnorm\n",
    "#from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(image_path)):\n",
    "    print(\"Processing\",image_path[i], i+1)\n",
    "    train_image = image.load_img('x_ray_image_recognition_data/x_ray_images/train_xray_images/'+image_path[i], target_size = (32, 32))\n",
    "    train_image = image.img_to_array(train_image)\n",
    "    train_image = np.expand_dims(train_image, axis = 0)\n",
    "    X_train.append(train_image)\n",
    "    y_train.append(y_desc_category_result[i])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(X_train, open(\"X_train.pickle\", \"wb\"))\n",
    "pickle.dump(y_train, open(\"y_train.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103462, 26)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(y_cat)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pickle.load(open(\"X_train.pickle\", \"rb\"))\n",
    "y_train = pickle.load(open(\"y_train.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103462, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X_temp = []\n",
    "for i in range(len(X_train)):\n",
    "    X_temp.append(X_train[i].reshape(32,32,3))\n",
    "X_train = np.array(X_temp)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize inputs from 0-255 to 0.0 - 1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20693, 26)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding to outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aayush\\AppData\\Local\\conda\\conda\\envs\\my_root_gpu\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2))`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 26)                13338     \n",
      "=================================================================\n",
      "Total params: 2,923,322\n",
      "Trainable params: 2,923,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(32,32,3), activation='relu', padding='same'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(26, activation='softmax'))\n",
    "\n",
    "# Compiling model\n",
    "epochs = 10\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(classifier.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 82769 samples, validate on 20693 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
